---
layout: page
title: 
subtitle: 
---
<div id="describe-text">
	
	<h2>PhD in Physics, Secondary in Data Science</h2>
  
	<h2>Research Interests: <strong>Machine Learning: Interpretability and Explainibility, Visualization of AI</strong></h2>
	
	<h3 align="left"> Current Projects: </h3>
	<p align="left"> 1. Interpreting Deep Neural Networks: Probing modularity and specialization in Neural Networks. Specialized Neurons emerge in Vision and Large Language Netowrks. Can we modify the current architecture to induce Specialization in an Interpretable way?   </p>
	<img src="{{ '/assets/img/branched.png' | prepend: site.baseurl }}" id="branched" width="800" align="center">
	<p align="left"> 2. Explainable AI: What is common between subsets of data within a clustered region in a t-SNE or UMAP projection of high-dimensional 			data? We're building the Next-gen Visualization tools that Visualization Clusters of Big data and Langauge, and explain what causes 			these clusters to form!</p>
		  
	<img src="{{ '/assets/img/clusters.png' | prepend: site.baseurl }}" id="clusters" width="800" align="center">
	<p align="left">3.  Data Visualization: Always curious about visualizing interesting datasets! </p>
</div>

---

<img src="{{ '/assets/img/pic.jpg' | prepend: site.baseurl }}" id="about-img">
This is me!
